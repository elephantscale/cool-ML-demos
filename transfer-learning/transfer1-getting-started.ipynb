{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Transfer Learning - Getting Started\n",
    "\n",
    "We will explore transfer learning concepts\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elephantscale/cool-ML-demos/blob/main/transfer-learning/transfer1-getting-started.ipynb)\n",
    "\n",
    "### Runtime\n",
    "~ 15 minutes\n",
    "\n",
    "### Note\n",
    "Here we are dealing with real world images.  Processing them will required a lot of compute power.  \n",
    "If you have access to, switch to **GPU** as run time!\n",
    "\n",
    "**Instructor** walk through this lab step-by-step and explain\n",
    "\n",
    "### References\n",
    "- https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "- [lmorony-dlaicourse](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%206%20-%20Lesson%203%20-%20Notebook.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print ('tensorflow version :', tf.__version__)\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6sLPjRC3vPG"
   },
   "source": [
    "## TF-GPU Config\n",
    "The following cell sets TF properties to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block is to tweak TF running on GPU\n",
    "## You may comment this out, if you are not using GPU\n",
    "\n",
    "## ---- start Memory setting ----\n",
    "## Ask TF not to allocate all GPU memory at once.. allocate as needed\n",
    "## Without this the execution will fail with \"failed to initialize algorithm\" error\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "## ---- end Memory setting ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model Summary Function\n",
    "This function only prints out the essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_summary_helper(line):\n",
    "    matches = ['Model:', 'Total params:', 'Trainable params:', 'Non-trainable params:']\n",
    "    if any(x in line for x in matches):\n",
    "        print(\"*\", line)\n",
    "\n",
    "def print_model_summary_compact(model):\n",
    "    model.summary(print_fn=compact_summary_helper)\n",
    "    # print (\"* model name:\", model.name)\n",
    "    print (\"* # layers: \", len(model.layers))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Download MobileNetv2 Model\n",
    "Here we will examine MobileNetv2 model.  MobileNetv2 was developed at Google.  It is pre-trained on the ImageNet dataset consisting of 1.4 Million images and 1000 classes.\n",
    "\n",
    "- paper: [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)\n",
    "- [github](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md)\n",
    "- [Tensorflow model page](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2)\n",
    "- [Tensorflow transfer learning guide](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "\n",
    "When downloading this model, the image dimension should be (224,224,3) to match Imagenet dimensions.\n",
    "\n",
    "We are also initializing the model with the weights of 'imagenet'\n",
    "\n",
    "#### TODO\n",
    "- Notice how many layers we have :-) \n",
    "- Look at the final `prediction` layer.  Why does it have 1000 neurons?\n",
    "- Look at `total parameters` and `total trainable parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), \n",
    "                                               include_top = True,\n",
    "                                               weights = 'imagenet')\n",
    "\n",
    "print (\"# layers: \", len(mobilenetv2_model.layers))\n",
    "\n",
    "## Warning: large output!\n",
    "mobilenetv2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Try Compact Summary\n",
    "Let's try our print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_summary_compact(mobilenetv2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's find the size of downloaded model\n",
    "! du -skh ~/.keras/models/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 -  Freeze Layers\n",
    "We are going to freeze the model.  \n",
    "See how many traininable parameters we  have now.  Compare with previous number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2_model.trainable = False\n",
    "print_model_summary_compact(mobilenetv2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Load Just the Base Model\n",
    "The last layer of MobileNet is for predicting 1000 classes of ImageNet.  \n",
    "For our purpose we don't need that.  \n",
    "So we are going to just load the baes model.  This is achieve by specifying `include_top=False`  \n",
    "Since we are not using the last layer, we can specify a custom image size other than (224,224,3)\n",
    "\n",
    "### TODO \n",
    "- Compare number of layers of full model and base model\n",
    "- Also compare number of trainable params of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(160,160,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "print (\"# layers: \", len(base_model.layers))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_summary_compact(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - InceptionV3 Model\n",
    "\n",
    "Inception achieved 79% accuracy in ImageNet data\n",
    "\n",
    "- [Reference paper](http://arxiv.org/abs/1512.00567)\n",
    "- [Tensorflow implementation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3)\n",
    "\n",
    "\n",
    "### TODO\n",
    "- How many model layers\n",
    "- How many model parameters\n",
    "- And inspect the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_model = tf.keras.applications.InceptionV3 (input_shape=(299,299,3), \n",
    "                                                        include_top = True,\n",
    "                                                        weights = 'imagenet')\n",
    "\n",
    "print_model_summary_compact(inceptionv3_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model sizes\n",
    "! du -skh ~/.keras/models/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Investigate other Models\n",
    "\n",
    "You can see other pre-trained models here.  \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
