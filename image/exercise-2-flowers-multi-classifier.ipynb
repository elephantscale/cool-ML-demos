{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Flowers Multi Classifier\n",
    "Learn to classify real world images\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elephantscale/cool-ML-demos/blob/main/image/exercise-2-flowers-multi-classifier.ipynb)\n",
    "\n",
    "### Runtime\n",
    "~30 minutes\n",
    "\n",
    "### Note\n",
    "Here we are dealing with real world images.  Processing them will required a lot of compute power.  \n",
    "If you have access to, switch to **GPU** run time!\n",
    "\n",
    "### Running on Google Colab?\n",
    "Be sure to upload 'image_utils.py'.  Here is how\n",
    "- Click on the left side bar\n",
    "- select the 'Files' section\n",
    "- Click the upload button and select `image_utils.py` file\n",
    "- If you change your runtime, you may need to upload the file again\n",
    "\n",
    "\n",
    "### References\n",
    "- https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print ('tensorflow version :', tf.__version__)\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading our custom utils files\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Hack to download image utils when running on Colab ..etc\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_url = 'https://raw.githubusercontent.com/elephantscale/es-public/master/deep-learning/image_utils.py'\n",
    "file_location = \"image_utils.py\"\n",
    "\n",
    "if not os.path.exists (file_location):\n",
    "    file_location = os.path.basename(file_location)\n",
    "    if not os.path.exists(file_location):\n",
    "        print(\"Downloading : \", file_url)\n",
    "        urllib.request.urlretrieve(file_url, file_location)\n",
    "print('file_location:', file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6sLPjRC3vPG"
   },
   "source": [
    "## TF-GPU Debug\n",
    "The following block tests if TF is running on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block is to tweak TF running on GPU\n",
    "## You may comment this out, if you are not using GPU\n",
    "\n",
    "## ---- start Memory setting ----\n",
    "## Ask TF not to allocate all GPU memory at once.. allocate as needed\n",
    "## Without this the execution will fail with \"failed to initialize algorithm\" error\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "## ---- end Memory setting ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Data\n",
    "\n",
    "Here are some stats on flowers dataset\n",
    "\n",
    "- Size : 230 MB\n",
    "- Number of files : ~3600\n",
    "- Has multiple classes:\n",
    "   - Dandelion\n",
    "   - Daisy\n",
    "   - Tulips\n",
    "   - Sunflowers\n",
    "   - Roses\n",
    "\n",
    "\n",
    "```text\n",
    "./flowers : files= 3671 , size= 230M\n",
    "./flowers/training : files= 3087 , size= 201M\n",
    "./flowers/training/dandelion : files= 776 , size= 43M\n",
    "./flowers/training/daisy : files= 533 , size= 30M\n",
    "./flowers/training/tulips : files= 677 , size= 49M\n",
    "./flowers/training/sunflowers : files= 588 , size= 48M\n",
    "./flowers/training/roses : files= 513 , size= 33M\n",
    "./flowers/validation : files= 583 , size= 29M\n",
    "./flowers/validation/dandelion : files= 122 , size= 5.6M\n",
    "./flowers/validation/daisy : files= 100 , size= 4.3M\n",
    "./flowers/validation/tulips : files= 122 , size= 5.8M\n",
    "./flowers/validation/sunflowers : files= 111 , size= 6.4M\n",
    "./flowers/validation/roses : files= 128 , size= 6.5M\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "data_location = 'https://elephantscale-public.s3.amazonaws.com/data/images/flowers.zip'\n",
    "\n",
    "data_location_local = keras.utils.get_file(fname=os.path.basename(data_location),\n",
    "                                           origin=data_location, extract=True)\n",
    "print ('local download file: ', data_location_local)\n",
    "\n",
    "## Peek inside the directory\n",
    "download_dir = os.path.dirname(data_location_local)\n",
    "print (\"download dir: \", download_dir )\n",
    "\n",
    "# print a nice tree\n",
    "! tree -d $download_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## peek inside our data dir\n",
    "data_dir = os.path.join(os.path.dirname(data_location_local), 'flowers')\n",
    "print ('here is how files are organized:')\n",
    "! tree -d $data_dir\n",
    "\n",
    "#listing = glob.glob(os.path.join(data_dir, \"**/*/\"), recursive=True)\n",
    "#for d in listing:\n",
    "#    print (d)\n",
    "\n",
    "print ('local data dir: ', data_dir)\n",
    "train_dir = os.path.join(data_dir, 'training')\n",
    "validation_dir = os.path.join(data_dir, 'validation')\n",
    "print ('train dir:', train_dir)\n",
    "print ('validation dir:', validation_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the images and get some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import print_training_validation_stats, display_images_from_dir\n",
    "\n",
    "print_training_validation_stats(train_dir, validation_dir)\n",
    "\n",
    "display_images_from_dir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "EPOCHS = 10\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "APP_NAME = 'flowers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Image Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## Here we are rescaling images by dividing it by 255\n",
    "## We are shuffling the images to increase randomness\n",
    "## Images are reshaped to 150x150\n",
    "\n",
    "\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "\n",
    "## TODO-Later\n",
    "## Add a train_image_generator with image augmentation\n",
    "\n",
    "train_image_generator = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=45,\n",
    "                            width_shift_range=.15,\n",
    "                            height_shift_range=.15,\n",
    "                            horizontal_flip=True,\n",
    "                            zoom_range=0.5\n",
    "                            )\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "\n",
    "## Since we only have two classes (cag/dog), we could have used 'binary' mode\n",
    "##            class_mode='binary'\n",
    "## But we are doing this as a 'multi-class-classifier' by specifying\n",
    "##            class_mode='categorical'\n",
    "## So the same code can work with multiple classes (cat/dog/horse/fox)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           # class_mode='binary'\n",
    "                                                           class_mode='categorical'\n",
    "                                                          )\n",
    "\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              # class_mode='binary'\n",
    "                                                              class_mode='categorical'\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "NUM_CLASSES = len(train_data_gen.class_indices)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.2),  \n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.2),  \n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.2),  \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# model.compile(#loss='binary_crossentropy',\n",
    "#               loss = 'categorical_crossentropy',\n",
    "#               optimizer=RMSprop(lr=0.001),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sU4Z4MYG3vPh"
   },
   "source": [
    "## Step 5 - Setup Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is fairly boiler plate code\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "app_name = APP_NAME\n",
    "\n",
    "\n",
    "# timestamp  = datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "tb_top_level_dir= '/tmp/tensorboard-logs'\n",
    "\n",
    "tb_app_dir = os.path.join (tb_top_level_dir, app_name)\n",
    "\n",
    "tb_logs_dir = os.path.join (tb_app_dir, datetime.datetime.now().strftime(\"%H-%M-%S\"))\n",
    "\n",
    "\n",
    "print (\"Saving TB logs to : \" , tb_logs_dir)\n",
    "\n",
    "#clear out old logs\n",
    "shutil.rmtree ( tb_app_dir, ignore_errors=True )\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_logs_dir, write_graph=True, \n",
    "                                                      write_images=True, histogram_freq=1)\n",
    "\n",
    "## This will embed Tensorboard right here in jupyter!\n",
    "# ! killall tensorboard  # kill previously running tensorboards\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $tb_logs_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cflnm-v23vPj"
   },
   "source": [
    "## Step 6 : Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch= train_data_gen.n // train_data_gen.batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.n // val_data_gen.batch_size,\n",
    "    callbacks = [tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model for reuse later\n",
    "As you can see training takes a long time.  \n",
    "Let's save the resulting model, so we can use it quickly without going through training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_file = APP_NAME + '-model.h5'\n",
    "model.save(model_file)\n",
    "\n",
    "model_size_in_bytes = os.path.getsize(model_file)\n",
    "print (\"model saved as '{}',  size = {:,f} bytes / {:,.1f} KB  / {:,.1f} MB\".format(model_file, \n",
    "                                    model_size_in_bytes, model_size_in_bytes / 1024, \n",
    "                                    model_size_in_bytes / (1024*1024) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9kZ2ul33vPm"
   },
   "source": [
    "## Step 7 : See Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmzupp1d3vPu"
   },
   "source": [
    "## Step 8 : Evaluate the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xF81OSSQ3vPv"
   },
   "source": [
    "### 8.1 - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "K8JoGQPJ3vPv",
    "outputId": "f8a19588-5045-4416-f0f3-9cdda95f376f"
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "metric_names = model.metrics_names\n",
    "print (\"model metrics : \" , metric_names)\n",
    "\n",
    "metrics = model.evaluate(val_data_gen, batch_size=val_data_gen.batch_size, steps=ceil(val_data_gen.n // val_data_gen.batch_size) )\n",
    "\n",
    "for idx, metric in enumerate(metric_names):\n",
    "    print (\"Metric : {} = {:,.3f}\".format (metric_names[idx], metrics[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 - Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "print (\"predicting on {:,} test images\".format(val_data_gen.n))\n",
    "# we need a ceiling for steps\n",
    "predictions = model.predict(val_data_gen, batch_size=val_data_gen.batch_size, \n",
    "                            steps=ceil(val_data_gen.n / val_data_gen.batch_size) )\n",
    "print( 'predictions.shape: ', predictions.shape)\n",
    "predictions2 = [ np.argmax(p) for p in predictions]\n",
    "\n",
    "# ## Ensure all predictions match\n",
    "assert(len(predictions) == len(predictions2) == len(val_data_gen.classes) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "\n",
    "print ('predictions : ' , predictions[:10])\n",
    "print ('prediction2: ' , predictions2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "test_labels = val_data_gen.classes\n",
    "cm = confusion_matrix(test_labels, predictions2, labels = range(0, NUM_CLASSES))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print (\"class index mapping : \", val_data_gen.class_indices)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm, annot=True, cmap=\"Reds\", fmt='d').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate the model\n",
    "What do you think of the model?\n",
    "- Look at learning curve.  Is there over/under fitting going on?\n",
    "- How is the accuracy?\n",
    "- What do you think of confusion matrix?\n",
    "\n",
    "See the visuzling below.\n",
    "\n",
    "**TODO: Discuss ways to increase accuracy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visually Inspecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import plot_prediction_stats_on_all_classes\n",
    "\n",
    "val_data_gen.reset() # reset back to batch-1\n",
    "plot_prediction_stats_on_all_classes(model, val_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup \n",
    "Before running the next exercise, run the following cell to terminate processes and free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kill any child processes (like tensorboard)\n",
    "\n",
    "import psutil\n",
    "import os, signal\n",
    "\n",
    "current_process = psutil.Process()\n",
    "children = current_process.children(recursive=True)\n",
    "for child in children:\n",
    "    print('Killing Child pid  {}'.format(child.pid))\n",
    "    os.kill(child.pid, signal.SIGKILL)\n",
    "    \n",
    "## This will kill actual kernel itself\n",
    "# os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
