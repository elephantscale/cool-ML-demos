{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Reusing a Model\n",
    "\n",
    "Here we are going to load a previously trained model and use it \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elephantscale/cool-ML-demos/blob/main/image/img5-reusing-a-model.ipynb)\n",
    "\n",
    "### Runtime\n",
    "15 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print ('tensorflow version :', tf.__version__)\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading our custom utils files\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Hack to download image utils when running on Colab ..etc\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_url = 'https://raw.githubusercontent.com/elephantscale/es-public/master/deep-learning/image_utils.py'\n",
    "file_location = \"image_utils.py\"\n",
    "\n",
    "if not os.path.exists (file_location):\n",
    "    file_location = os.path.basename(file_location)\n",
    "    if not os.path.exists(file_location):\n",
    "        print(\"Downloading : \", file_url)\n",
    "        urllib.request.urlretrieve(file_url, file_location)\n",
    "print('file_location:', file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6sLPjRC3vPG"
   },
   "source": [
    "## TF-GPU Debug\n",
    "The following block tests if TF is running on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block is to tweak TF running on GPU\n",
    "## You may comment this out, if you are not using GPU\n",
    "\n",
    "## ---- start Memory setting ----\n",
    "## Ask TF not to allocate all GPU memory at once.. allocate as needed\n",
    "## Without this the execution will fail with \"failed to initialize algorithm\" error\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "## ---- end Memory setting ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Cats-Dogs\n",
    "\n",
    "BATCH_SIZE=128\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "SAVED_MODEL_FILE='cat-dog-model.h5'\n",
    "\n",
    "import os\n",
    "\n",
    "data_location = 'https://elephantscale-public.s3.amazonaws.com/data/images/cat-dog-redux.zip'\n",
    "\n",
    "data_location_local = keras.utils.get_file(fname=os.path.basename(data_location),\n",
    "                                           origin=data_location, extract=True)\n",
    "print ('local download file: ', data_location_local)\n",
    "data_dir = os.path.join(os.path.dirname(data_location_local), 'cat-dog-redux')\n",
    "print ('local data dir: ', data_dir)\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'val')\n",
    "print ('train dir:', train_dir)\n",
    "print ('validation dir:', validation_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Horses or Humans\n",
    "\n",
    "# BATCH_SIZE=32\n",
    "# IMG_HEIGHT = 300\n",
    "# IMG_WIDTH = 300\n",
    "# SAVED_MODEL_FILE='horse-human-model.h5'\n",
    "\n",
    "# import os\n",
    "\n",
    "# data_location = ' https://elephantscale-public.s3.amazonaws.com/data/images/horse-or-human.zip'\n",
    "# data_location_local = keras.utils.get_file(fname=os.path.basename(data_location),\n",
    "#                                            origin=data_location, extract=True)\n",
    "# print ('local download file: ', data_location_local)\n",
    "\n",
    "# ## Peek inside the directory\n",
    "# # download_dir = os.path.dirname(data_location_local)\n",
    "# # print (\"download dir: \", download_dir )\n",
    "\n",
    "# # print a nice tree\n",
    "# # ! tree -d $download_dir\n",
    "\n",
    "# ## if the above doesn't work, use the one below\n",
    "# # print (\"listing of download dir: \", os.listdir(os.path.dirname(data_location_local)))\n",
    "\n",
    "# data_dir = os.path.join(os.path.dirname(data_location_local), 'horse-or-human')\n",
    "\n",
    "# # peek inside data dir\n",
    "# # ! tree -d $data_dir\n",
    "\n",
    "# # print ('local data dir: ', data_dir)\n",
    "# train_dir = os.path.join(data_dir, 'train')\n",
    "# validation_dir = os.path.join(data_dir, 'validation')\n",
    "# print ('train dir:', train_dir)\n",
    "# print ('validation dir:', validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Prepare a Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_gen = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "\n",
    "data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              # class_mode='binary'\n",
    "                                                              class_mode='categorical'\n",
    "                                                             )\n",
    "\n",
    "label_mappings = data_gen.class_indices\n",
    "print (\"label mappings : \", label_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = next(data_gen)\n",
    "# print (x)\n",
    "# print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "model_file = SAVED_MODEL_FILE\n",
    "model_size_in_bytes = os.path.getsize(model_file)\n",
    "\n",
    "\n",
    "model = load_model(model_file)\n",
    "\n",
    "print (\"Loaded model '{}',  size = {} bytes / {:,.1f} KB  / {:,.1f} MB\".format(model_file, \n",
    "                                    model_size_in_bytes, model_size_in_bytes / 1024, \n",
    "                                    model_size_in_bytes / (1024*1024) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Predict on all validation/test images\n",
    "Here is how we run prediction on all images in one shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "print (\"predicting on {:,} test images\".format(data_gen.n))\n",
    "# we need a ceiling for steps\n",
    "predictions = model.predict(data_gen, batch_size=data_gen.batch_size, \n",
    "                            steps=ceil(data_gen.n / data_gen.batch_size) )\n",
    "print( 'predictions.shape: ', predictions.shape)\n",
    "\n",
    "if data_gen.class_mode == 'categorical':\n",
    "    # converting softmax --> classes\n",
    "    print (\"convering softmax --> classes\")\n",
    "    predictions2 = [ np.argmax(p) for p in predictions]\n",
    "\n",
    "if data_gen.class_mode == 'binary':\n",
    "    # converting sigmoid --> classes\n",
    "    print (\"converting sigmod --> binary\")\n",
    "    predictions2 = [0 if n < 0.5 else 1 for n in predictions]\n",
    "\n",
    "\n",
    "# ## Ensure all predictions match\n",
    "assert(len(predictions) == len(predictions2) == len(data_gen.classes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Predict on a Single Image\n",
    "Sometimes we just want to predict on certain images.  \n",
    "Here is how.  \n",
    "Note how we are loading images and shaping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Every time you run this cell, we will process a random image\n",
    "\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print (\"image directory: \", data_gen.directory)\n",
    "print (\"label mappings: \", label_mappings)\n",
    "\n",
    "index = random.randint(0, data_gen.n-1)\n",
    "\n",
    "image_file = data_gen.filepaths[index]\n",
    "print (\"image file: \", image_file)\n",
    "img = image.load_img(image_file, target_size = (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "# scale the data\n",
    "img_data = image.img_to_array(img) / 255.0\n",
    "\n",
    "## we need to shape the date to match the input shape network is expecting\n",
    "# option 1 reshape\n",
    "#img_data = np.expand_dims(img_data, axis = 0)\n",
    "#prediction = model.predict (image_data)\n",
    "# or option 2: no reshape and predict\n",
    "prediction = model.predict(img_data[None]) # this is softmax output\n",
    "print ('softmax output: ', prediction)\n",
    "\n",
    "index_of_highest_probability = np.argmax(prediction[0])\n",
    "value_of_highest_probability = prediction[0][index_of_highest_probability]\n",
    "\n",
    "print (\"predicted class: \", index_of_highest_probability, \", probability:\", value_of_highest_probability)\n",
    "\n",
    "## plot the image\n",
    "plt.imshow(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Predict on Custom Images\n",
    "Let's predict on some of our 'own' images (images that are not part of training/validation set).  \n",
    "The simplest approach is to copy image files into a directory.\n",
    "\n",
    "- we have some sample images that were not part of the  dataset in subdirectories of `my-images` directory\n",
    "- Download some pictures and put them into a a subdirectory of `my-images`  (e.g  `my-images/cat-dog`)\n",
    "- And the following code will predict on them\n",
    "- For fun, also include pictures of 'not seen' labels.  For example if the model trained on  cats-and-dog, feed the model 'human-or-horse' and see what happens :-) \n",
    "\n",
    "Here are some websites that offer free images:\n",
    "- https://www.pexels.com/\n",
    "- https://pixabay.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from image_utils import   predict_on_images_in_dir, plot_image_predictions\n",
    "import pprint\n",
    "\n",
    "my_images_dir = 'my-images/horse-human'\n",
    "\n",
    "prediction_results = predict_on_images_in_dir(model, my_images_dir, IMG_WIDTH, IMG_HEIGHT)\n",
    "# pprint.pprint (prediction_results)\n",
    "\n",
    "plot_image_predictions(prediction_results, \"Predict on sample images\", label_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Explore Predictions on classes\n",
    "This a fun experiment to visually see how our model is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import plot_prediction_stats_on_all_classes\n",
    "\n",
    "data_gen.reset() # reset back to batch-1\n",
    "plot_prediction_stats_on_all_classes(model, data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
